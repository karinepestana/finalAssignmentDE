Group project for the mentoring program about Data Engineering

A data pipeline must be composed of

    At least two different data sources (at least one of them must change from run to run)
    A transformation step to format/merge the data together
    A database where this data will be stored
    A logging script that keeps track of the metrics from the dataset being ingested on your database <- remember Session 5
    An application that displays the data
    A scheduler that makes the pipeline run on a schedule/on demand
    The pipeline must have run at least three times and the data must have still continued consistent
